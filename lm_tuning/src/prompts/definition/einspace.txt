Search Space Definition:
The search space includes groups of operations which can represent many state-of-the-art neural architectures.
The search space is based on context free grammar and each candidate represnets a syntax tree of the architecture.

The four fundamental operations are:
1. Branching: One-to-many functions that direct the flow of information through the network by cloning
 or splitting tensors. Examples include the branching within self-attention modules into queries, keys
 and values.
2. Aggregation: Many-to-one functions that merge the information from multiple tensors into one.
 Examples include matrix multiplication, summation and concatenation.
3. Routing: One-to-one functions that change the shape or the order of the content in a tensor without
 altering its information. Examples include axis permutations as well as the im2col and col2im
 operations. 
4. Computation: One-to-one functions that alter the information of the tensor, either by parameterised
 operations, normalisation or non-linearities. Examples include linear layers, batchnorm and activations
 like ReLU and softmax.

The two feature modes are:
1. Im mode: Maintains a 3D tensor of shape (C, H, W), where C is the number of channels, H is the
 height and W is the width. Most convolutional architectures operate in this mode.
2. Col mode: Maintains a 2D tensor of shape(S, D),where S is the sequence length and D is the token
 dimensionality. This is the mode in which most transformer architectures operate.

For each candidate in the search space, its format is described using functions formatted as below:
1. Branching functions:
    branching(b)[M] - where b is the number of splits/clones, M is a set of other operations.
    clone(b) - cloning b copies of the tensor.
    group(b,dim) - splitting tensor into b parts along dimension dim.
2. Aggregation functions:
    dot_product(scaled) - matrix multiplication with optional scaling
    add - summation of multiple tensors.
    concat(b,dim) - concatenate b tensors along dimension d.
3. Routing functions:
    routing[M] - where M is a set of other operations.
    im2col(k,s,p) - convert from im mode to col mode, where k is kernel size, s is the stride and p the padding.
    col2im - convert from col mode to im mode.
    permute(o) - same as permute function in pytorch.
    identity - keep original tensor.
4. Computation functions:
    computation<o> - where o could be any functions listed below.
    linear(d) - linear layers with d as the output dimension.
    norm - batch-norm functionality in the Im mode and layer-norm in Col mode. 
    softmax - softmax operation applied to the final dimension.
    relu - leaky relu activation function.
    pos-enc -positional encoding.

An example representation of a traditional convolutional block with a skip connection:
branching(2){clone(2),sequential(sequential(routing[im2col(8,8,0), computation<linear>, col2im]), sequential(computation<norm>, computation<relu>)), computation<identity>, add(2)}
